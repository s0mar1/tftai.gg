/**
 * GraphQL ë°°ì¹˜ ì¿¼ë¦¬ ë° ë©€í‹°í”Œë ‰ì‹± ìµœì í™” ì‹œìŠ¤í…œ
 * ì—¬ëŸ¬ í´ë¼ì´ì–¸íŠ¸ì˜ ìœ ì‚¬í•œ ìš”ì²­ì„ ë°°ì¹˜ ì²˜ë¦¬í•˜ì—¬ ì„±ëŠ¥ ìµœì í™”
 */

import logger from '../config/logger';
import graphqlResponseCache from './responseCache';
import { GraphQLPerformanceTracker } from './telemetry';

/**
 * ë°°ì¹˜ ìš”ì²­ ì¸í„°í˜ì´ìŠ¤
 */
interface BatchRequest {
  id: string;
  operation: string;
  args: Record<string, any>;
  timestamp: number;
  resolve: (result: any) => void;
  reject: (error: Error) => void;
  complexity: number;
}

/**
 * ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼
 */
interface BatchExecutionResult {
  batchId: string;
  requests: BatchRequest[];
  executionTime: number;
  cacheHits: number;
  errors: number;
}

/**
 * ë°°ì¹˜ ì¿¼ë¦¬ ìµœì í™” ê´€ë¦¬ì
 */
export class BatchQueryOptimizer {
  private pendingRequests = new Map<string, BatchRequest[]>();
  private batchTimers = new Map<string, NodeJS.Timeout>();
  private readonly BATCH_WINDOW_MS = 50; // 50ms ë°°ì¹˜ ìœˆë„ìš°
  private readonly MAX_BATCH_SIZE = 10; // ìµœëŒ€ ë°°ì¹˜ í¬ê¸°
  private readonly MIN_BATCH_SIZE = 2; // ìµœì†Œ ë°°ì¹˜ í¬ê¸°
  private batchExecutionHistory: BatchExecutionResult[] = [];

  /**
   * ë°°ì¹˜ ê°€ëŠ¥í•œ ìš”ì²­ì¸ì§€ í™•ì¸
   */
  private isBatchable(operation: string, args: Record<string, any>): boolean {
    // ë°°ì¹˜ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì‘ì—…ë“¤
    const batchableOperations = ['champions', 'tierlist'];
    
    if (!batchableOperations.includes(operation)) {
      return false;
    }
    
    // ì‚¬ìš©ìë³„ ë°ì´í„°ëŠ” ë°°ì¹˜í•˜ì§€ ì•ŠìŒ
    if (args.name || args.puuid || args.userId) {
      return false;
    }
    
    return true;
  }

  /**
   * ë°°ì¹˜ í‚¤ ìƒì„± (ìœ ì‚¬í•œ ìš”ì²­ë“¤ì„ ê·¸ë£¹í™”)
   */
  private generateBatchKey(operation: string, args: Record<string, any>): string {
    // languageë¥¼ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì¸ìë¡œ ë°°ì¹˜ í‚¤ ìƒì„±
    const { language, ...otherArgs } = args;
    const batchArgs = Object.keys(otherArgs).length > 0 ? JSON.stringify(otherArgs) : '';
    return `${operation}:${batchArgs}`;
  }

  /**
   * ë°°ì¹˜ ìš”ì²­ ì¶”ê°€
   */
  async addToBatch<T>(
    operation: string,
    args: Record<string, any>,
    complexity: number = 1,
    executor: (batchedArgs: Record<string, any>[]) => Promise<T[]>
  ): Promise<T> {
    // ë°°ì¹˜ ë¶ˆê°€ëŠ¥í•œ ìš”ì²­ì€ ì¦‰ì‹œ ì‹¤í–‰
    if (!this.isBatchable(operation, args)) {
      logger.debug(`ğŸ”„ [Batch] ì¦‰ì‹œ ì‹¤í–‰: ${operation}`);
      const results = await executor([args]);
      return results[0];
    }

    const batchKey = this.generateBatchKey(operation, args);
    const requestId = `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    return new Promise<T>((resolve, reject) => {
      const request: BatchRequest = {
        id: requestId,
        operation,
        args,
        timestamp: Date.now(),
        resolve,
        reject,
        complexity
      };

      // ë°°ì¹˜ì— ìš”ì²­ ì¶”ê°€
      if (!this.pendingRequests.has(batchKey)) {
        this.pendingRequests.set(batchKey, []);
      }
      
      const batch = this.pendingRequests.get(batchKey)!;
      batch.push(request);

      logger.debug(`ğŸ“¦ [Batch] ìš”ì²­ ì¶”ê°€: ${operation} (${batch.length}/${this.MAX_BATCH_SIZE})`);

      // ìµœëŒ€ ë°°ì¹˜ í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì¦‰ì‹œ ì‹¤í–‰
      if (batch.length >= this.MAX_BATCH_SIZE) {
        this.executeBatch(batchKey, executor);
      } else {
        // íƒ€ì´ë¨¸ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì„¤ì •
        if (!this.batchTimers.has(batchKey)) {
          const timer = setTimeout(() => {
            this.executeBatch(batchKey, executor);
          }, this.BATCH_WINDOW_MS);
          
          this.batchTimers.set(batchKey, timer);
        }
      }
    });
  }

  /**
   * ë°°ì¹˜ ì‹¤í–‰
   */
  private async executeBatch<T>(
    batchKey: string,
    executor: (batchedArgs: Record<string, any>[]) => Promise<T[]>
  ): Promise<void> {
    const batch = this.pendingRequests.get(batchKey);
    if (!batch || batch.length === 0) return;

    // íƒ€ì´ë¨¸ ì •ë¦¬
    const timer = this.batchTimers.get(batchKey);
    if (timer) {
      clearTimeout(timer);
      this.batchTimers.delete(batchKey);
    }

    // ë°°ì¹˜ì—ì„œ ì œê±°
    this.pendingRequests.delete(batchKey);

    logger.info(`ğŸš€ [Batch] ë°°ì¹˜ ì‹¤í–‰: ${batchKey} (${batch.length}ê°œ ìš”ì²­)`);

    const batchId = `batch_${Date.now()}_${Math.random().toString(36).substr(2, 6)}`;
    const startTime = Date.now();
    let cacheHits = 0;
    let errors = 0;

    try {
      // ìºì‹œì—ì„œ ë¨¼ì € í™•ì¸
      const cachedResults: (T | null)[] = [];
      const uncachedRequests: BatchRequest[] = [];
      const uncachedIndices: number[] = [];

      for (let i = 0; i < batch.length; i++) {
        const request = batch[i];
        const cached = await graphqlResponseCache.get<T>(request.operation, request.args);
        
        if (cached) {
          cachedResults[i] = cached.data;
          cacheHits++;
          logger.debug(`ğŸ¯ [Batch Cache] íˆíŠ¸: ${request.operation}`);
        } else {
          cachedResults[i] = null;
          uncachedRequests.push(request);
          uncachedIndices.push(i);
        }
      }

      // ìºì‹œë˜ì§€ ì•Šì€ ìš”ì²­ë“¤ë§Œ ì‹¤í–‰
      if (uncachedRequests.length > 0) {
        logger.debug(`âš¡ [Batch] ì‹¤ì œ ì‹¤í–‰: ${uncachedRequests.length}ê°œ ìš”ì²­`);
        
        const batchedArgs = uncachedRequests.map(req => req.args);
        const results = await executor(batchedArgs);

        // ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥í•˜ê³  ì‘ë‹µ
        for (let i = 0; i < uncachedRequests.length; i++) {
          const request = uncachedRequests[i];
          const result = results[i];
          const originalIndex = uncachedIndices[i];
          
          cachedResults[originalIndex] = result;

          // ìºì‹œì— ì €ì¥
          await graphqlResponseCache.set(
            request.operation,
            request.args,
            result,
            { 
              complexity: request.complexity,
              tags: [request.operation],
              ttl: 600 // 10ë¶„ ê¸°ë³¸ ìºì‹œ
            },
            request.id,
            Date.now() - startTime
          );
        }

        // DataLoader ë°°ì¹˜ ì¶”ì 
        GraphQLPerformanceTracker.traceDataLoaderBatch(
          `batch_${batchKey}`,
          uncachedRequests.length,
          cacheHits
        );
      }

      // ëª¨ë“  ìš”ì²­ì— ê²°ê³¼ ë°˜í™˜
      for (let i = 0; i < batch.length; i++) {
        const request = batch[i];
        const result = cachedResults[i];
        
        if (result !== null) {
          request.resolve(result);
        } else {
          errors++;
          request.reject(new Error(`ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤: ${request.operation}`));
        }
      }

    } catch (error: any) {
      logger.error(`âŒ [Batch] ë°°ì¹˜ ì‹¤í–‰ ì‹¤íŒ¨: ${batchKey}`, error);
      
      // ëª¨ë“  ìš”ì²­ì— ì—ëŸ¬ ë°˜í™˜
      batch.forEach(request => {
        request.reject(error);
        errors++;
      });
    }

    const executionTime = Date.now() - startTime;
    
    // ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼ ê¸°ë¡
    const result: BatchExecutionResult = {
      batchId,
      requests: batch,
      executionTime,
      cacheHits,
      errors
    };
    
    this.batchExecutionHistory.push(result);
    
    // íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
    if (this.batchExecutionHistory.length > 100) {
      this.batchExecutionHistory.shift();
    }

    logger.info(`âœ… [Batch] ë°°ì¹˜ ì™„ë£Œ: ${batchKey} - ${executionTime}ms, ìºì‹œ íˆíŠ¸: ${cacheHits}, ì—ëŸ¬: ${errors}`);
  }

  /**
   * ë°°ì¹˜ ì„±ëŠ¥ í†µê³„
   */
  getBatchStats(): any {
    if (this.batchExecutionHistory.length === 0) {
      return {
        totalBatches: 0,
        averageExecutionTime: 0,
        averageBatchSize: 0,
        cacheHitRate: 0,
        errorRate: 0
      };
    }

    const totalBatches = this.batchExecutionHistory.length;
    const totalExecutionTime = this.batchExecutionHistory.reduce((sum, batch) => sum + batch.executionTime, 0);
    const totalRequests = this.batchExecutionHistory.reduce((sum, batch) => sum + batch.requests.length, 0);
    const totalCacheHits = this.batchExecutionHistory.reduce((sum, batch) => sum + batch.cacheHits, 0);
    const totalErrors = this.batchExecutionHistory.reduce((sum, batch) => sum + batch.errors, 0);

    return {
      totalBatches,
      totalRequests,
      averageExecutionTime: Math.round(totalExecutionTime / totalBatches),
      averageBatchSize: Math.round(totalRequests / totalBatches),
      cacheHitRate: Math.round((totalCacheHits / totalRequests) * 100),
      errorRate: Math.round((totalErrors / totalRequests) * 100),
      recentBatches: this.batchExecutionHistory.slice(-5).map(batch => ({
        batchId: batch.batchId,
        requestCount: batch.requests.length,
        executionTime: batch.executionTime,
        cacheHits: batch.cacheHits
      }))
    };
  }

  /**
   * í˜„ì¬ ëŒ€ê¸° ì¤‘ì¸ ë°°ì¹˜ ìƒíƒœ
   */
  getPendingBatchStatus(): any {
    const pendingStatus = Array.from(this.pendingRequests.entries()).map(([key, requests]) => ({
      batchKey: key,
      requestCount: requests.length,
      oldestRequest: Math.min(...requests.map(r => r.timestamp)),
      avgComplexity: requests.reduce((sum, r) => sum + r.complexity, 0) / requests.length
    }));

    return {
      pendingBatches: this.pendingRequests.size,
      totalPendingRequests: Array.from(this.pendingRequests.values()).reduce((sum, batch) => sum + batch.length, 0),
      batches: pendingStatus
    };
  }
}

/**
 * ë©€í‹°í”Œë ‰ì‹± ìµœì í™” ê´€ë¦¬ì
 * ì¤‘ë³µëœ ìš”ì²­ì„ í•˜ë‚˜ë¡œ í•©ì³ì„œ ì²˜ë¦¬
 */
export class MultiplexingOptimizer {
  private inflightRequests = new Map<string, Promise<any>>();
  private requestCounts = new Map<string, number>();

  /**
   * ìš”ì²­ í‚¤ ìƒì„±
   */
  private generateRequestKey(operation: string, args: Record<string, any>): string {
    return `${operation}:${JSON.stringify(args, Object.keys(args).sort())}`;
  }

  /**
   * ë©€í‹°í”Œë ‰ì‹± ìµœì í™”ëœ ìš”ì²­
   */
  async multiplex<T>(
    operation: string,
    args: Record<string, any>,
    executor: () => Promise<T>
  ): Promise<T> {
    const requestKey = this.generateRequestKey(operation, args);
    
    // ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ë™ì¼í•œ ìš”ì²­ì´ ìˆëŠ”ì§€ í™•ì¸
    if (this.inflightRequests.has(requestKey)) {
      const count = this.requestCounts.get(requestKey) || 0;
      this.requestCounts.set(requestKey, count + 1);
      
      logger.debug(`ğŸ”„ [Multiplex] ì¤‘ë³µ ìš”ì²­ ëŒ€ê¸°: ${operation} (${count + 1}ê°œ í´ë¼ì´ì–¸íŠ¸)`);
      
      return this.inflightRequests.get(requestKey) as Promise<T>;
    }

    // ìƒˆë¡œìš´ ìš”ì²­ ì‹¤í–‰
    this.requestCounts.set(requestKey, 1);
    
    const promise = executor()
      .then(result => {
        const clientCount = this.requestCounts.get(requestKey) || 1;
        
        logger.info(`âœ… [Multiplex] ìš”ì²­ ì™„ë£Œ: ${operation} (${clientCount}ê°œ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡)`);
        
        return result;
      })
      .catch(error => {
        logger.error(`âŒ [Multiplex] ìš”ì²­ ì‹¤íŒ¨: ${operation}`, error);
        throw error;
      })
      .finally(() => {
        // ì™„ë£Œëœ ìš”ì²­ ì •ë¦¬
        this.inflightRequests.delete(requestKey);
        this.requestCounts.delete(requestKey);
      });
    
    this.inflightRequests.set(requestKey, promise);
    
    return promise;
  }

  /**
   * ë©€í‹°í”Œë ‰ì‹± í†µê³„
   */
  getMultiplexStats(): any {
    const inflightCount = this.inflightRequests.size;
    const totalClients = Array.from(this.requestCounts.values()).reduce((sum, count) => sum + count, 0);

    return {
      inflightRequests: inflightCount,
      totalClients,
      averageClientsPerRequest: inflightCount > 0 ? Math.round(totalClients / inflightCount) : 0,
      requests: Array.from(this.requestCounts.entries()).map(([key, count]) => ({
        operation: key.split(':')[0],
        clientCount: count
      }))
    };
  }
}

// ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë“¤
export const batchQueryOptimizer = new BatchQueryOptimizer();
export const multiplexingOptimizer = new MultiplexingOptimizer();

// í†µí•© ìµœì í™” í•¨ìˆ˜
export async function optimizedGraphQLExecution<T>(
  operation: string,
  args: Record<string, any>,
  complexity: number,
  executor: (batchedArgs?: Record<string, any>[]) => Promise<T[] | T>
): Promise<T> {
  // 1. ë©€í‹°í”Œë ‰ì‹±ìœ¼ë¡œ ì¤‘ë³µ ìš”ì²­ ì œê±°
  return multiplexingOptimizer.multiplex(
    operation,
    args,
    async () => {
      // 2. ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
      return batchQueryOptimizer.addToBatch(
        operation,
        args,
        complexity,
        async (batchedArgs: Record<string, any>[]) => {
          const results = await executor(batchedArgs);
          return Array.isArray(results) ? results : [results];
        }
      );
    }
  );
}

/**
 * í†µí•© ìµœì í™” í†µê³„
 */
export function getOptimizationStats() {
  return {
    batch: batchQueryOptimizer.getBatchStats(),
    pending: batchQueryOptimizer.getPendingBatchStatus(),
    multiplex: multiplexingOptimizer.getMultiplexStats(),
    timestamp: new Date().toISOString()
  };
}